{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13ab77be",
   "metadata": {},
   "source": [
    "# Assigning speeches to their proper orator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "559c5e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fef5d4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define custom speech class\n",
    "class Speech:\n",
    "    def __init__(self, text, orator):\n",
    "        self.text = text\n",
    "        self.orator = orator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c10410e",
   "metadata": {},
   "source": [
    "# Importing and preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "586aca7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'clinton'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = './data/all_speeches.csv'\n",
    "\n",
    "df = pd.read_csv(file_name)\n",
    "\n",
    "#Set each speech entry as custom class\n",
    "speeches = []\n",
    "for index, row in df.iterrows():\n",
    "    speech = {'text':row['text'], 'orator':row['orator']} \n",
    "    speeches.append(Speech(speech['text'], speech['orator']))\n",
    "\n",
    "speeches[99].orator # Change orator to text to access speech text data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55e5680",
   "metadata": {},
   "source": [
    "# Splitting training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "0491a5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 99\n",
    "train, test = train_test_split(speeches, test_size=.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "c26514c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = [x.text for x in train]\n",
    "train_y = [x.orator for x in train]\n",
    "\n",
    "test_x = [x.text for x in test]\n",
    "test_y = [x.orator for x in test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f96259",
   "metadata": {},
   "source": [
    "# Vectorize with Bags of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "94b44971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Bags of Words Count Vectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "#vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit vectorizer to training data, and transformed to provide vectors\n",
    "train_x_vectors = vectorizer.fit_transform(train_x)\n",
    "\n",
    "test_x_vectors = vectorizer.transform(test_x)\n",
    "\n",
    "# Final Variables\n",
    "# train_x_vectors\n",
    "# train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd25693a",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "7813f313",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['bush',\n",
    "              'clinton',\n",
    "              'obama',\n",
    "              'trump']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1db322",
   "metadata": {},
   "source": [
    "#### K Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "01203f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_neighbors=3) ACCURACY:  0.3125\n",
      "[0.36363636 0.28571429 0.35714286 0.14285714]\n"
     ]
    }
   ],
   "source": [
    "clf_knn = KNeighborsClassifier(n_neighbors=3)\n",
    "clf_knn.fit(train_x_vectors, train_y)\n",
    "\n",
    "# Accuracy readouts\n",
    "print(model,'ACCURACY: ', model.score(test_x_vectors, test_y))\n",
    "print(f1_score(test_y, model.predict(test_x_vectors), average=None, labels=categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8b1dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using GridSearch to check on parameters \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292fe23e",
   "metadata": {},
   "source": [
    "# Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "39c13b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./knn_model.pkl', 'wb') as f:\n",
    "    pickle.dump(clf_knn, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c325bb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model\n",
    "# with open('/knn_model.pkl', 'rb') as f:\n",
    "#     loaded_clf_knn = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
